![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Framework](https://img.shields.io/badge/Framework-TensorFlow%202.x-orange)
![Architecture](https://img.shields.io/badge/Architecture-CNN-blueviolet)
![Dataset](https://img.shields.io/badge/Dataset-CIFAR--10-brightgreen)
![Augmentation](https://img.shields.io/badge/Data%20Augmentation-Enabled-success)
![Regularization](https://img.shields.io/badge/BatchNorm%20%2B%20Dropout-Used-informational)
![Callbacks](https://img.shields.io/badge/Callbacks-EarlyStopping%20%7C%20LR%20Scheduler-yellow)
![Evaluation](https://img.shields.io/badge/Evaluation-Confusion%20Matrix-blue)
![Accuracy](https://img.shields.io/badge/Test%20Accuracy-82--88%25-success)

ğŸš€ Practical 1 â€” Enhanced CIFAR-10 Image Classification using CNN
ğŸ“Œ Overview

This project implements an enhanced Convolutional Neural Network (CNN) for multi-class image classification on the CIFAR-10 dataset using TensorFlow 2.x and Keras.

The implementation follows a structured 7-step pipeline while integrating practical deep learning best practices such as:

Data normalization

One-hot encoding

Data augmentation

Batch normalization

Dropout regularization

Learning rate scheduling

Early stopping

Model checkpointing

Confusion matrix and classification report analysis

The goal is not just to train a CNN, but to build a stable, generalizable, and reproducible training pipeline.

ğŸ§  Dataset: CIFAR-10

CIFAR-10 is a benchmark dataset consisting of:

60,000 RGB images

Image size: 32 Ã— 32

10 object categories

50,000 training images

10,000 test images

Classes:

airplane, automobile, bird, cat, deer,
dog, frog, horse, ship, truck


This dataset is challenging because:

Images are small (low resolution)

Some classes have overlapping visual features (e.g., cat vs dog)

Intra-class variability is high

ğŸ— Project Pipeline (7-Step Structure)
ğŸ”¹ Step 1: Import Required Libraries

All necessary libraries are imported:

TensorFlow / Keras for deep learning

NumPy for numerical operations

Matplotlib & Seaborn for visualization

sklearn for evaluation metrics

This separation ensures clarity and modular structure.

ğŸ”¹ Step 2: Load and Prepare Dataset
Key preprocessing steps:
1ï¸âƒ£ Normalization

Pixel values are scaled from:

[0, 255] â†’ [0, 1]


This improves:

Numerical stability

Convergence speed

Gradient behavior

Without normalization, training becomes unstable.

2ï¸âƒ£ One-Hot Encoding

Labels are converted from integer format:

3 â†’ [0,0,0,1,0,0,0,0,0,0]


Why?

Because the model uses:

loss = categorical_crossentropy


Which requires probability distributions rather than scalar labels.

ğŸ”¹ Step 3: Data Augmentation

Data augmentation artificially increases training diversity.

Techniques used:

Random rotation

Width shift

Height shift

Horizontal flipping

Why this matters:

Without augmentation:

Model memorizes training samples

Overfitting increases

Validation accuracy plateaus early

With augmentation:

Model generalizes better

Learns rotation/translation invariance

Test accuracy improves by ~5â€“10%

ğŸ”¹ Step 4: CNN Architecture Design

The architecture consists of:

ğŸ”¸ Convolution Blocks

Each block includes:

Conv2D

Batch Normalization

Conv2D

Batch Normalization

MaxPooling

Dropout

Why this structure?
âœ” Convolution Layers

Extract spatial features (edges â†’ textures â†’ shapes â†’ objects).

âœ” Batch Normalization

Stabilizes training

Reduces internal covariate shift

Allows higher learning rates

Speeds up convergence

âœ” MaxPooling

Reduces spatial dimensions while preserving important features.

âœ” Dropout

Prevents overfitting by randomly disabling neurons during training.

Dropout rates increase deeper in the network:

0.25 â†’ 0.3 â†’ 0.4 â†’ 0.5

This progressively increases regularization strength.

ğŸ”¸ Fully Connected Layer

Dense(256)

BatchNorm

Dropout(0.5)

Acts as classifier head after spatial features are flattened.

ğŸ”¸ Output Layer
Dense(10, activation='softmax')


Softmax ensures:

Probabilities sum to 1

Multi-class classification compatibility

âš™ Step 5: Model Compilation

Optimizer used:

Adam (learning_rate = 0.001)


Why Adam?

Adaptive learning rate

Faster convergence

Good default for most CNN tasks

Loss function:

categorical_crossentropy


Metric:

accuracy

ğŸ‹ Step 6: Training Strategy

This is where the model becomes serious.

Three critical callbacks are used:

1ï¸âƒ£ ModelCheckpoint

Saves the best model based on validation accuracy.

Prevents losing best weights due to overfitting later epochs.

2ï¸âƒ£ EarlyStopping

Stops training if validation loss stops improving.

Benefits:

Prevents overfitting

Saves training time

Keeps best weights

3ï¸âƒ£ ReduceLROnPlateau

If validation loss plateaus:

Learning rate is reduced

This allows:

Fine-grained convergence

Escaping shallow minima

Without LR scheduling, models often plateau early.

ğŸ“Š Step 7: Evaluation & Analysis

Evaluation includes:

âœ” Final Test Accuracy

Measured on unseen data.

Expected accuracy:

~82% â€“ 88%


(depending on hardware & randomness)

âœ” Training vs Validation Curves

Used to diagnose:

Overfitting

Underfitting

Convergence behavior

If:

Training accuracy >> Validation accuracy â†’ Overfitting

Both low â†’ Underfitting

âœ” Classification Report

Provides:

Precision

Recall

F1-score

Support

More informative than accuracy alone.

âœ” Confusion Matrix

Shows:

Which classes are misclassified

Confusion patterns (e.g., cat vs dog)

Useful for real error analysis.

ğŸ“ˆ Expected Performance
Model Type	Accuracy
Basic CNN	~70â€“75%
Enhanced CNN (this project)	~82â€“88%
Transfer Learning	90%+

This project intentionally avoids transfer learning to demonstrate fundamental CNN construction.

ğŸ“¦ Project Structure
cifar10_cnn/
â”‚
â”œâ”€â”€ Practical1_CNN.ipynb
â”œâ”€â”€ best_cifar10_model.h5
â””â”€â”€ README.md

ğŸ›  Installation & Execution
Install Dependencies
pip install tensorflow numpy matplotlib seaborn scikit-learn

Run Notebook
jupyter notebook


Run cells sequentially from Step 1 to Step 7.

ğŸ§© Design Decisions & Trade-offs
Why not use ResNet?

Because this practical focuses on:

Understanding CNN fundamentals

Manual architecture construction

Observing effect of regularization

Why not use Transfer Learning?

Transfer learning hides architectural understanding.

This implementation forces you to understand:

Feature extraction

Pooling effects

Regularization balance

Learning rate behavior

ğŸš€ Future Improvements

If this were production-level:

Use EfficientNet / ResNet

Add MixUp / CutMix augmentation

Use Cosine Learning Rate Scheduling

Implement Label Smoothing

Perform Hyperparameter tuning

Add TensorBoard logging

Use Stratified validation split

ğŸ¯ Key Takeaways

This project demonstrates:

âœ” How to design CNN blocks properly
âœ” Why batch normalization matters
âœ” Why dropout placement is critical
âœ” How callbacks stabilize training
âœ” Why evaluation requires more than accuracy
âœ” How to structure a clean training pipeline

ğŸ Conclusion

This is not just a CNN implementation.

It is a structured, regularized, and controlled image classification pipeline designed with real training principles.

The objective was not maximum accuracy.

The objective was:

Stability, generalization, and clarity of architectural decisions.
