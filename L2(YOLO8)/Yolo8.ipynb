{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gDp0SUaftJ8o"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.4.9)\n","Requirement already satisfied: numpy\u003e=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib\u003e=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python\u003e=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.13.0.90)\n","Requirement already satisfied: pillow\u003e=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml\u003e=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch\u003e=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n","Requirement already satisfied: torchvision\u003e=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n","Requirement already satisfied: psutil\u003e=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars\u003e=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n","Requirement already satisfied: ultralytics-thop\u003e=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.3.3)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (4.61.1)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.4.9)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (25.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (3.3.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.4.4)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.11)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2026.1.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.20.3)\n","Requirement already satisfied: typing-extensions\u003e=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (75.2.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (1.14.0)\n","Requirement already satisfied: networkx\u003e=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.1.6)\n","Requirement already satisfied: fsspec\u003e=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (2025.3.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.3.0-\u003eultralytics) (1.17.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch\u003e=1.8.0-\u003eultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-\u003etorch\u003e=1.8.0-\u003eultralytics) (3.0.3)\n","Requirement already satisfied: yt-dlp in /usr/local/lib/python3.12/dist-packages (2026.1.29)\n","Ultralytics YOLOv8 ready\n","Custom model not found, loading pretrained yolov8n.pt\n","Model loaded ✓\n","Downloading YouTube Shorts video...\n","[youtube] Extracting URL: https://www.youtube.com/shorts/Ek5cKd3pnB4?feature=share\n","[youtube] Ek5cKd3pnB4: Downloading webpage\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n"]},{"name":"stdout","output_type":"stream","text":["[youtube] Ek5cKd3pnB4: Downloading android vr player API JSON\n","[youtube] Ek5cKd3pnB4: Downloading ios downgraded player API JSON\n","[youtube] Ek5cKd3pnB4: Downloading m3u8 information\n","[info] Testing format 620\n","[info] Ek5cKd3pnB4: Downloading 1 format(s): 620+140\n","[download] /content/shorts_video.mp4 has already been downloaded\n","Downloaded video: /content/shorts_video.mp4\n","Running YOLOv8 and saving annotated video...\n","End of video reached.\n","Annotated video saved: /content/annotated_shorts.mp4\n","Displaying full annotated video below:\n","Buffered data was truncated after reaching the output size limit."]}],"source":["# =============================================================================\n","# Practical 4: Real-time Object Detection with YOLOv8 (YouTube Shorts → full annotated video)\n","# Course:           Computer Vision\n","# Objective:        Run YOLOv8 on a YouTube Shorts video and see full video with detections\n","# Tools:            Python + Ultralytics YOLOv8 + yt-dlp\n","# =============================================================================\n","\n","\n","# Step 0: Install required packages (run once)\n","!pip install ultralytics\n","!pip install yt-dlp\n","\n","\n","from ultralytics import YOLO\n","import cv2\n","import os\n","import yt_dlp\n","from IPython.display import HTML\n","from base64 import b64encode\n","\n","\n","print(\"Ultralytics YOLOv8 ready\")\n","\n","\n","# ========================================================================\n","# Step 1: Define paths (Colab)\n","# ========================================================================\n","\n","# Path to your dataset (if you want to train later)\n","DATASET_PATH = \"/content/images\"   # folder containing images/, labels/, data.yaml\n","\n","# Path to your trained model weights (after training)\n","MODEL_PATH = os.path.join(\n","    \"runs\", \"detect\", \"your_custom_model\", \"weights\", \"best.pt\"\n",")\n","\n","# Directory where the Shorts video will be saved\n","OUTPUT_DIR = \"/content\"\n","INPUT_VIDEO = os.path.join(OUTPUT_DIR, \"shorts_video.mp4\")\n","OUTPUT_VIDEO = os.path.join(OUTPUT_DIR, \"annotated_shorts.mp4\")\n","\n","# Training run name (used in runs/detect/your_custom_model)\n","TRAIN_NAME = \"your_custom_model\"\n","\n","\n","# ========================================================================\n","# Step 2: Train custom YOLOv8 model (run once, optional)\n","# ========================================================================\n","\n","# Uncomment this block only when you want to train your custom model\n","\"\"\"\n","print(\"Starting training...\")\n","\n","model = YOLO(\"yolov8n.pt\")   # nano model (fastest)\n","\n","model.train(\n","    data=os.path.join(DATASET_PATH, \"data.yaml\"),\n","    epochs=50,      # adjust as needed\n","    imgsz=640,      # image size\n","    batch=16,       # reduce if you get out-of-memory errors\n","    name=TRAIN_NAME # saves to runs/detect/TRAIN_NAME\n",")\n","\n","print(\"Training finished!\")\n","\"\"\"\n","\n","\n","# ========================================================================\n","# Step 3: Load trained model (or pretrained if not trained yet)\n","# ========================================================================\n","\n","# Option A: Use your custom trained model\n","if os.path.exists(MODEL_PATH):\n","    print(f\"Loading custom model from: {MODEL_PATH}\")\n","    model = YOLO(MODEL_PATH)\n","else:\n","    print(\"Custom model not found, loading pretrained yolov8n.pt\")\n","    model = YOLO(\"yolov8n.pt\")\n","\n","print(\"Model loaded ✓\")\n","\n","\n","# ========================================================================\n","# Step 4: Download YouTube Shorts video (your URL)\n","# ========================================================================\n","\n","# Your YouTube Shorts URL\n","YOUTUBE_URL = \"https://www.youtube.com/shorts/Ek5cKd3pnB4?feature=share\"\n","\n","ydl_opts = {\n","    \"format\": \"bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best\",\n","    \"outtmpl\": INPUT_VIDEO,\n","    \"merge_output_format\": \"mp4\",\n","}\n","\n","print(\"Downloading YouTube Shorts video...\")\n","with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n","    ydl.download([YOUTUBE_URL])\n","\n","print(f\"Downloaded video: {INPUT_VIDEO}\")\n","\n","\n","# ========================================================================\n","# Step 5: Run YOLOv8 and save full annotated video\n","# ========================================================================\n","\n","cap = cv2.VideoCapture(INPUT_VIDEO)\n","\n","if not cap.isOpened():\n","    print(\"Error: Cannot open video file\")\n","    exit()\n","\n","# Get video properties\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Define codec and create VideoWriter\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (width, height))\n","\n","print(\"Running YOLOv8 and saving annotated video...\")\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        print(\"End of video reached.\")\n","        break\n","\n","    # Run YOLOv8 inference\n","    results = model(frame, verbose=False)\n","\n","    # Draw results on frame (bounding boxes, labels, confidence)\n","    annotated_frame = results[0].plot()\n","\n","    # Write annotated frame to output video\n","    out.write(annotated_frame)\n","\n","cap.release()\n","out.release()\n","print(f\"Annotated video saved: {OUTPUT_VIDEO}\")\n","\n","\n","# ========================================================================\n","# Step 6: Display full annotated video in Colab\n","# ========================================================================\n","\n","# Convert video to base64 so it can be embedded in HTML\n","with open(OUTPUT_VIDEO, \"rb\") as f:\n","    video_bytes = f.read()\n","video_b64 = b64encode(video_bytes).decode()\n","\n","video_html = f\"\"\"\n","\u003cvideo width=\"800\" controls\u003e\n","  \u003csource src=\"data:video/mp4;base64,{video_b64}\" type=\"video/mp4\"\u003e\n","  Your browser does not support the video tag.\n","\u003c/video\u003e\n","\"\"\"\n","\n","print(\"Displaying full annotated video below:\")\n","display(HTML(video_html))\n","\n","\n","# ========================================================================\n","# Optional: Run on a single image or save output\n","# ========================================================================\n","\n","# Example: run on one image\n","results = model(\"/content/438159029_1112336846689554_6666657298374937680_n_jpg.rf.ef8d85be9ab7c620ead05befd5352e50.jpg\")\n","results[0].save(\"result.jpg\")\n","\n","print(\"You can uncomment the optional section above to run on a single image.\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPeuJDfXn0wWOu1l23A/kOp","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}