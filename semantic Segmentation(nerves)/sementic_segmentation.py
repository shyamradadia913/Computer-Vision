# -*- coding: utf-8 -*-
"""sementic_segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LmF_bbEBjxKYTnmsQyNDL1EkW5v7BDBq
"""

!pip install tifffile

# COMPLETE U-Net Training Pipeline - Fixed for your dataset
# Only loads images WITH matching masks âœ“ Handles LZW compression âœ“

import os
import glob
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from PIL import Image
import tifffile

print("TensorFlow version:", tf.__version__)
print("GPU Available:", tf.config.list_physical_devices('GPU'))

# ============================================================================
# 1. BUILD U-Net MODEL (Your existing model - PERFECT)
# ============================================================================
def unet_model(input_size=(128, 128, 1)):
    inputs = layers.Input(input_size)

    # Encoder
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = layers.BatchNormalization()(c1)
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    c1 = layers.BatchNormalization()(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)

    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = layers.BatchNormalization()(c2)
    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    c2 = layers.BatchNormalization()(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)

    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = layers.BatchNormalization()(c3)
    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    c3 = layers.BatchNormalization()(c3)
    p3 = layers.MaxPooling2D((2, 2))(c3)

    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = layers.BatchNormalization()(c4)
    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)
    c4 = layers.BatchNormalization()(c4)
    p4 = layers.MaxPooling2D((2, 2))(c4)

    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    c5 = layers.BatchNormalization()(c5)
    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)
    c5 = layers.BatchNormalization()(c5)

    # Decoder
    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = layers.concatenate([u6, c4])
    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)
    c6 = layers.BatchNormalization()(c6)
    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)
    c6 = layers.BatchNormalization()(c6)

    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = layers.concatenate([u7, c3])
    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)
    c7 = layers.BatchNormalization()(c7)
    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)
    c7 = layers.BatchNormalization()(c7)

    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = layers.concatenate([u8, c2])
    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)
    c8 = layers.BatchNormalization()(c8)
    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)
    c8 = layers.BatchNormalization()(c8)

    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = layers.concatenate([u9, c1])
    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)
    c9 = layers.BatchNormalization()(c9)
    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)
    c9 = layers.BatchNormalization()(c9)

    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)

    return models.Model(inputs=[inputs], outputs=[outputs])

model = unet_model()
model.summary()
print("U-Net model ready âœ“")

# ============================================================================
# 2. FIXED DATA LOADER - Only images WITH masks
# ============================================================================
def load_valid_pairs_only(folder_path, target_size=(128, 128)):
    """
    Loads ONLY image-mask pairs that exist together.
    Skips any image without matching mask.
    Handles LZW compression automatically.
    """
    tif_files = glob.glob(os.path.join(folder_path, "*.tif")) + \
                glob.glob(os.path.join(folder_path, "*.tiff"))

    # Get all potential base images (no "_mask" in name)
    image_paths = [p for p in tif_files if "_mask" not in os.path.basename(p).lower()]
    image_paths.sort()

    print(f"Scanning {len(image_paths)} potential images...")

    X, Y = [], []

    for img_path in image_paths:
        # Construct exact mask filename
        base_name = os.path.splitext(os.path.basename(img_path))[0]
        mask_path = os.path.join(folder_path, f"{base_name}_mask.tif")

        # ONLY proceed if mask exists
        if not os.path.exists(mask_path):
            continue

        try:
            # Load image
            img_array = tifffile.imread(img_path)
            if len(img_array.shape) == 3:
                img_array = img_array[0] if img_array.shape[0] == 1 else img_array[:, :, 0]

            img_pil = Image.fromarray(img_array).convert('L').resize(target_size)
            img = np.array(img_pil, dtype=np.float32) / 255.0

            # Load mask
            mask_array = tifffile.imread(mask_path)
            if len(mask_array.shape) == 3:
                mask_array = mask_array[0] if mask_array.shape[0] == 1 else mask_array[:, :, 0]

            mask_pil = Image.fromarray(mask_array).convert('L').resize(target_size)
            mask = np.array(mask_pil, dtype=np.float32) / 255.0
            mask = (mask > 0.1).astype(np.float32)  # Threshold for tumor

            X.append(img[..., np.newaxis])
            Y.append(mask[..., np.newaxis])

        except Exception as e:
            print(f"Failed to load {os.path.basename(img_path)}: {e}")
            continue

    print(f"âœ“ Loaded {len(X)} VALID image-mask pairs")
    return np.array(X), np.array(Y)

# ============================================================================
# 3. LOAD DATA
# ============================================================================
DATA_FOLDER = "/content/data"
print(f"\nLoading data from: {DATA_FOLDER}")

# Install imagecodecs if needed (handles LZW)
try:
    import imagecodecs
    print("imagecodecs is already installed.")
except ImportError:
    print("imagecodecs not found. Installing...")
    import subprocess, sys
    subprocess.check_call([sys.executable, "-m", "pip", "install", "imagecodecs"])
    print("imagecodecs has been installed. Please restart the Colab runtime (Runtime -> Restart runtime) for changes to take full effect.")
    # Exit to ensure the user restarts the runtime for imagecodecs to be properly picked up.
    sys.exit("Restarting Colab runtime is necessary after installing imagecodecs.")

x_all, y_all = load_valid_pairs_only(DATA_FOLDER)

if len(x_all) == 0:
    print("âŒ No valid image-mask pairs found!")
    print("Check if your masks are named as: IMAGE_NAME_mask.tif and if imagecodecs is properly installed.")
    exit()

print(f"Dataset shape: {x_all.shape}")
print(f"Mask shape:   {y_all.shape}")
print(f"Tumor pixels: {np.mean(y_all):.1%}")

# Train/Val split (80/20)
split_idx = int(0.8 * len(x_all))
x_train, x_val = x_all[:split_idx], x_all[split_idx:]
y_train, y_val = y_all[:split_idx], y_all[split_idx:]

print(f"\nTrain: {x_train.shape}")
print(f"Val:   {x_val.shape}")

# ============================================================================
# 4. COMPILE & TRAIN
# ============================================================================
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss='binary_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)

# Callbacks
callbacks = [
    tf.keras.callbacks.ModelCheckpoint('best_unet.h5', save_best_only=True, monitor='val_loss'),
    tf.keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5),
    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
]

# TRAIN
print("\nðŸš€ Starting training...")
history = model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=50,
    batch_size=8,
    callbacks=callbacks,
    verbose=1
)

print("âœ… Training complete! Best model saved as 'best_unet.h5'")

# Visualize predictions
import matplotlib.pyplot as plt
predictions = model.predict(x_val)

fig, axes = plt.subplots(2, 4, figsize=(16, 8))
for i in range(min(4, len(x_val))):
    # Row 1: Input + GT + Prediction
    axes[0,i].imshow(x_val[i].squeeze(), cmap='gray')
    axes[0,i].set_title(f'Input {i+1}')
    axes[1,i].imshow(y_val[i].squeeze(), cmap='Reds')
    axes[1,i].imshow(predictions[i].squeeze() > 0.5, cmap='Blues', alpha=0.6)
    axes[1,i].set_title(f'GT + Pred {i+1}')
plt.tight_layout()
plt.show()

# Print metrics
print("Dice Score:", 2 * np.mean((predictions > 0.5) * y_val) / (np.mean(predictions > 0.5) + np.mean(y_val) + 1e-8))

model.save('tumor_segmenter.h5')  # 118MB file - your tumor detector!
print("âœ… Model saved! Download tumor_segmenter.h5")